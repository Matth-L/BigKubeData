import sys
import os
import subprocess
from time import sleep
import socket 

###################################
# MYSQL
###################################
import mysql.connector
from mysql.connector import Error

###################################
# ELASTICSEARCH
###################################
from elasticsearch import Elasticsearch
from elasticsearch.exceptions import AuthenticationException
from elasticsearch.helpers import bulk 
import logging
from elasticsearch.exceptions import NotFoundError

###################################
# FAKER, to build random data
###################################
from faker import Faker
fake = Faker()

# Enabling logging so that we can see it in K8S Logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  
        logging.FileHandler('app.log', mode='a')
    ]
)
logger = logging.getLogger()

# the adress of the mysql database in the k8s cluster
mysql_host = "mysql.default.svc.cluster.local"

try:
    logger.info(f"Resolving {mysql_host}...")
    ip = socket.gethostbyname(mysql_host)
    logger.info(f"DNS resolution successful: {mysql_host} â†’ {ip}")
except socket.gaierror as e:
    logger.error(f"DNS resolution failed: {e}")

def get_db():
    """
    Connects to the database and returns a database object

    return : the cursor to the databse
    """
    db = mysql.connector.connect(
    host=mysql_host,
    user="root",
    password="password",
    database="data",
    port=3306
)
    return db

def get_data_from_db():
    """
    we will use this function once, to put all the database in elastic search
    
    return : the database with the query done

    """
    db = get_db()
    
    if db.is_connected():
        logger.info("Successfully connected to the database.")

    cursor = db.cursor()
    cursor.execute("SELECT * FROM student")  
    results = cursor.fetchall()
    cursor.close()
    db.close()
    return results

def get_elastic_client(password):
    """
    connect using the http authentification and the password generated by ELASTIC 
    when creating the pod, changes everytime it is launched in a new pod, so loaded as a paremeter

    return : elastic client
    """
    client = Elasticsearch(
    "https://quickstart-es-http.default.svc:9200",
    http_auth=("elastic", password),
    verify_certs=False
    ) 

    try:
        response = client.info()
    except AuthenticationException:
        print("Authentication failed. Please check your credentials.")
    except Exception as e:
        print(f"Error connecting to Elasticsearch: {e}")

    return client
    

def is_data_in_es(client, doc_id, index_name):
    """
    Check if the data already exists in Elasticsearch by `id`.
    """
    try:
        response = client.get(index=index_name, id=doc_id)
        logger.info(f"Document found: {response}")
        return True
    except NotFoundError:
        logger.info(f"Document with id {doc_id} not found in index {index_name}.")
        return False
    except Exception as e:
        logger.error(f"An error occurred: {e}")
        return False


def insert_to_elasticsearch(client, mysql_data,index_name):
    """
    Insert the data in elasticserach, checks if the data are already in the db so there 
    is no duplicatas
    """
    actions = []
    for row in mysql_data:
        doc_id = row[0] 
        logger.info(f"ID: {(row[0])}")
        if not is_data_in_es(client,doc_id,index_name):
            action = {
                "_op_type": "index",
                "_index": index_name, 
                "_id": doc_id, 
                "_source": {
                    "first_name": row[1], 
                    "last_name": row[2],
                    "age" : row[3]
                }
            }
            actions.append(action)
    success, failed = bulk(client, actions, index=index_name)
    logger.info(f"Inserted {success} records. Failed: {failed}.")

def insert_random_students(number_of_records):
    """
    Uses faker to insert random data in the database
    """
    db = get_db()
    cursor = db.cursor()

    # Insert random student data
    for _ in range(number_of_records):
        first_name = fake.first_name()
        last_name = fake.last_name()
        age = fake.random_int(min=10, max=100)  
        
        insert_query = """
            INSERT INTO student (first_name, last_name, age) 
            VALUES (%s, %s, %s)
        """
        values = (first_name, last_name, age)    
        cursor.execute(insert_query, values)
    db.commit()
    cursor.close()
    db.close()



if __name__ == "__main__":
    
    # load the password from the env
    password = os.getenv('PASSWORD')

    es_client = get_elastic_client(password)
    index_name = "students_data"
    random_insertion = 5
    sleeping_time=20

    for _ in range(10):
        # select all values
        mysql_data = get_data_from_db()
        #push new values to elastic search
        insert_to_elasticsearch(es_client,mysql_data,index_name) 
        logger.info("Sleeping for 20 seconds before next operation...")
        sleep(sleeping_time)
        logger.info("Inserting random data...")
        insert_random_students(random_insertion)


